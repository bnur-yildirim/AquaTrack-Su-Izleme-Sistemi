"""
Su Kalitesi API Route'larÄ± - K-Means Clustering BazlÄ±
Data leakage olmayan, gerÃ§ek spektral analiz
"""

from flask import Blueprint, request, jsonify
import pandas as pd
import numpy as np
import pickle
import os
from datetime import datetime
from config import LAKE_INFO, KEY_BY_ID
from utils import log_info, log_error

water_quality_bp = Blueprint('water_quality', __name__)

# Base directory - Backend directory (where water_quality folder is copied)
# __file__ = backend/routes/water_quality_routes.py
# parent x2 = backend/routes -> backend
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# Model ve scaler'Ä± global olarak yÃ¼kle
KMEANS_MODEL = None
SCALER = None
CLUSTER_FEATURES = None

def load_models():
    """K-Means modelini ve scaler'Ä± yÃ¼kle"""
    global KMEANS_MODEL, SCALER, CLUSTER_FEATURES
    
    try:
        # Proje root'undan modelleri yÃ¼kle
        model_path = os.path.join(BASE_DIR, 'models_external', 'kmeans_water_quality.pkl')
        scaler_path = os.path.join(BASE_DIR, 'models_external', 'scaler_water_quality.pkl')
        
        if os.path.exists(model_path):
            with open(model_path, 'rb') as f:
                KMEANS_MODEL = pickle.load(f)
            log_info("âœ… K-Means model yÃ¼klendi")
        
        if os.path.exists(scaler_path):
            with open(scaler_path, 'rb') as f:
                SCALER = pickle.load(f)
            log_info("âœ… Scaler yÃ¼klendi")
        
        # Cluster Ã¶zellikleri
        CLUSTER_FEATURES = {
            0: {
                "name": "Normal Su Kalitesi",
                "description": "Standart temiz su profili. DÃ¼ÅŸÃ¼k turbidite, orta NDWI, dÃ¼ÅŸÃ¼k klorofil.",
                "color": "#10b981",  # YeÅŸil
                "icon": "ðŸŸ¢",
                "risk_level": "DÃ¼ÅŸÃ¼k",
                "recommendations": [
                    "Su kalitesi normal sÄ±nÄ±rlarda",
                    "Rutin izleme yeterli",
                    "Mevsimsel deÄŸiÅŸimler izlenmeli"
                ]
            },
            1: {
                "name": "Alg PatlamasÄ± Riski",
                "description": "Ekstrem yÃ¼ksek klorofil-a deÄŸerleri. Alg bloom olaylarÄ±.",
                "color": "#ef4444",  # KÄ±rmÄ±zÄ±
                "icon": "ðŸ”´",
                "risk_level": "YÃ¼ksek",
                "recommendations": [
                    "Acil izleme gerektirir",
                    "Besin maddesi kirliliÄŸi kontrol edilmeli",
                    "Su kullanÄ±mÄ± sÄ±nÄ±rlandÄ±rÄ±lmalÄ±"
                ]
            },
            2: {
                "name": "Tuzlu Su Ã–zellikleri",
                "description": "Tuzlu gÃ¶l karakteristikleri. DÃ¼ÅŸÃ¼k turbidite, yÃ¼ksek mineral iÃ§erik.",
                "color": "#3b82f6",  # Mavi
                "icon": "ðŸ”µ",
                "risk_level": "Normal",
                "recommendations": [
                    "Tuzlu gÃ¶l iÃ§in normal profil",
                    "Tuz konsantrasyonu izlenmeli",
                    "Ekolojik denge korunmalÄ±"
                ]
            },
            3: {
                "name": "Ã–zel CoÄŸrafi Durum",
                "description": "Alkalin/soda gÃ¶l Ã¶zellikleri. YÃ¼ksek pH, Ã¶zel mineral iÃ§erik.",
                "color": "#8b5cf6",  # Mor
                "icon": "ðŸŸ£",
                "risk_level": "Ã–zel",
                "recommendations": [
                    "GÃ¶le Ã¶zgÃ¼ Ã¶zel durum",
                    "Jeolojik Ã¶zellikler etkili",
                    "DoÄŸal durum, mÃ¼dahale gerektirmez"
                ]
            }
        }
        
        return True
        
    except Exception as e:
        log_error(f"Model yÃ¼kleme hatasÄ±: {e}")
        return False

# Uygulama baÅŸlatÄ±ldÄ±ÄŸÄ±nda modelleri yÃ¼kle
load_models()


@water_quality_bp.route("/api/water-quality/predict", methods=["POST"])
def predict_water_quality():
    """
    Su kalitesi cluster tahmini (K-Means)
    
    Body: {
        "ndwi_mean": 5.26,
        "wri_mean": 1206.05,
        "chl_a_mean": 1212.66,
        "turbidity_mean": 0.54
    }
    
    Response: {
        "cluster": 0,
        "cluster_name": "Normal Su Kalitesi",
        "description": "...",
        "risk_level": "DÃ¼ÅŸÃ¼k",
        "color": "#10b981",
        "icon": "ðŸŸ¢",
        "recommendations": [...],
        "spectral_values": {...}
    }
    """
    if KMEANS_MODEL is None or SCALER is None:
        return jsonify({"error": "Model yÃ¼klenemedi"}), 500
    
    try:
        data = request.json
        
        # Feature'larÄ± al
        features = np.array([[
            float(data.get('ndwi_mean', 0)),
            float(data.get('wri_mean', 0)),
            float(data.get('chl_a_mean', 0)),
            float(data.get('turbidity_mean', 0))
        ]])
        
        # Normalize
        features_scaled = SCALER.transform(features)
        
        # Cluster tahmini
        cluster = int(KMEANS_MODEL.predict(features_scaled)[0])
        
        # Cluster bilgilerini al
        cluster_info = CLUSTER_FEATURES.get(cluster, CLUSTER_FEATURES[0])
        
        # Mesafe hesapla (gÃ¼ven skoru iÃ§in)
        distances = KMEANS_MODEL.transform(features_scaled)[0]
        confidence = 1 - (distances[cluster] / np.sum(distances))
        
        result = {
            "status": "success",
            "cluster": cluster,
            "cluster_name": cluster_info["name"],
            "description": cluster_info["description"],
            "risk_level": cluster_info["risk_level"],
            "color": cluster_info["color"],
            "icon": cluster_info["icon"],
            "confidence": round(float(confidence), 3),
            "recommendations": cluster_info["recommendations"],
            "spectral_values": {
                "ndwi_mean": float(data.get('ndwi_mean', 0)),
                "wri_mean": float(data.get('wri_mean', 0)),
                "chl_a_mean": float(data.get('chl_a_mean', 0)),
                "turbidity_mean": float(data.get('turbidity_mean', 0))
            },
            "timestamp": datetime.now().isoformat()
        }
        
        return jsonify(result)
        
    except Exception as e:
        log_error(f"Tahmin hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500


@water_quality_bp.route("/api/water-quality/batch", methods=["POST"])
def batch_predict_water_quality():
    """
    Toplu su kalitesi tahmini (zaman serisi iÃ§in)
    
    Body: {
        "lake_id": 141,
        "measurements": [
            {"date": "2024-01-01", "ndwi_mean": 5.26, "wri_mean": 1206.05, ...},
            {"date": "2024-02-01", "ndwi_mean": 5.30, "wri_mean": 1210.00, ...},
            ...
        ]
    }
    """
    if KMEANS_MODEL is None or SCALER is None:
        return jsonify({"error": "Model yÃ¼klenemedi"}), 500
    
    try:
        data = request.json
        lake_id = data.get('lake_id')
        measurements = data.get('measurements', [])
        
        if not measurements:
            return jsonify({"error": "Ã–lÃ§Ã¼m verisi yok"}), 400
        
        results = []
        
        for measurement in measurements:
            # Feature'larÄ± hazÄ±rla
            features = np.array([[
                float(measurement.get('ndwi_mean', 0)),
                float(measurement.get('wri_mean', 0)),
                float(measurement.get('chl_a_mean', 0)),
                float(measurement.get('turbidity_mean', 0))
            ]])
            
            # Normalize ve tahmin
            features_scaled = SCALER.transform(features)
            cluster = int(KMEANS_MODEL.predict(features_scaled)[0])
            cluster_info = CLUSTER_FEATURES.get(cluster, CLUSTER_FEATURES[0])
            
            # GÃ¼ven skoru
            distances = KMEANS_MODEL.transform(features_scaled)[0]
            confidence = 1 - (distances[cluster] / np.sum(distances))
            
            results.append({
                "date": measurement.get('date'),
                "cluster": cluster,
                "cluster_name": cluster_info["name"],
                "risk_level": cluster_info["risk_level"],
                "confidence": round(float(confidence), 3),
                "spectral_values": {
                    "ndwi_mean": float(measurement.get('ndwi_mean', 0)),
                    "wri_mean": float(measurement.get('wri_mean', 0)),
                    "chl_a_mean": float(measurement.get('chl_a_mean', 0)),
                    "turbidity_mean": float(measurement.get('turbidity_mean', 0))
                }
            })
        
        return jsonify({
            "status": "success",
            "lake_id": lake_id,
            "total_measurements": len(results),
            "results": results
        })
        
    except Exception as e:
        log_error(f"Toplu tahmin hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500


@water_quality_bp.route("/api/water-quality/lake-analysis/<lake_id>", methods=["GET"])
def lake_analysis(lake_id):
    """
    Belirli bir gÃ¶l iÃ§in geÃ§miÅŸ su kalitesi analizi
    data/b5_b11_combined_features.csv dosyasÄ±ndan veri Ã§eker
    """
    try:
        # CSV dosyasÄ±nÄ± oku (proje root'undan)
        csv_path = os.path.join(BASE_DIR, 'water_quality', 'data', 'clustered_water_quality.csv')
        
        if not os.path.exists(csv_path):
            return jsonify({"error": f"Spektral veri dosyasÄ± bulunamadÄ±: {csv_path}"}), 404
        
        df = pd.read_csv(csv_path)
        
        # Lake ID'yi numerik'e Ã§evir
        if lake_id.isdigit():
            lake_numeric_id = int(lake_id)
        else:
            # Ä°simden ID'ye Ã§evir
            lake_key = lake_id.lower()
            if lake_key in LAKE_INFO:
                lake_numeric_id = LAKE_INFO[lake_key]["id"]
            else:
                return jsonify({"error": f"GÃ¶l bulunamadÄ±: {lake_id}"}), 404
        
        # Lake name mapping
        lake_names = {
            140: 'Tuz GÃ¶lÃ¼',
            141: 'Van GÃ¶lÃ¼',
            1321: 'Ulubat GÃ¶lÃ¼',
            1340: 'EÄŸirdir GÃ¶lÃ¼',
            1342: 'Burdur GÃ¶lÃ¼',
            14510: 'Sapanca GÃ¶lÃ¼',
            14741: 'Salda GÃ¶lÃ¼'
        }
        
        lake_name = lake_names.get(lake_numeric_id)
        if not lake_name:
            return jsonify({"error": f"GÃ¶l {lake_id} bulunamadÄ±"}), 404
        
        # GÃ¶l verilerini filtrele
        lake_data = df[df['lake_name'] == lake_name].copy()
        
        if lake_data.empty:
            return jsonify({"error": f"GÃ¶l {lake_id} iÃ§in veri bulunamadÄ±"}), 404
        
        # Cluster tahminlerini hesapla
        features = lake_data[['ndwi_mean', 'wri_mean', 'chl_a_mean', 'turbidity_mean']].values
        features_scaled = SCALER.transform(features)
        clusters = KMEANS_MODEL.predict(features_scaled)
        
        lake_data['cluster'] = clusters
        
        # Ä°statistikler
        cluster_distribution = lake_data['cluster'].value_counts().to_dict()
        
        # Zaman serisi verileri
        time_series = []
        for _, row in lake_data.iterrows():
            cluster_info = CLUSTER_FEATURES.get(int(row['cluster']), CLUSTER_FEATURES[0])
            time_series.append({
                "date": row['date'],
                "cluster": int(row['cluster']),
                "cluster_name": cluster_info["name"],
                "risk_level": cluster_info["risk_level"],
                "ndwi_mean": float(row['ndwi_mean']),
                "wri_mean": float(row['wri_mean']),
                "chl_a_mean": float(row['chl_a_mean']),
                "turbidity_mean": float(row['turbidity_mean'])
            })
        
        # Ortalama deÄŸerler
        avg_values = {
            "ndwi_mean": float(lake_data['ndwi_mean'].mean()),
            "wri_mean": float(lake_data['wri_mean'].mean()),
            "chl_a_mean": float(lake_data['chl_a_mean'].mean()),
            "turbidity_mean": float(lake_data['turbidity_mean'].mean())
        }
        
        # BaskÄ±n cluster
        dominant_cluster = int(lake_data['cluster'].mode()[0])
        dominant_info = CLUSTER_FEATURES.get(dominant_cluster, CLUSTER_FEATURES[0])
        
        result = {
            "status": "success",
            "lake_id": lake_numeric_id,
            "lake_name": lake_data['lake_name'].iloc[0] if 'lake_name' in lake_data.columns else f"Lake {lake_numeric_id}",
            "total_measurements": len(lake_data),
            "date_range": {
                "start": lake_data['date'].min(),
                "end": lake_data['date'].max()
            },
            "dominant_cluster": {
                "cluster": dominant_cluster,
                "name": dominant_info["name"],
                "percentage": round(float(cluster_distribution.get(dominant_cluster, 0) / len(lake_data) * 100), 2),
                "risk_level": dominant_info["risk_level"]
            },
            "cluster_distribution": {
                str(k): {
                    "count": int(v),
                    "percentage": round(float(v / len(lake_data) * 100), 2),
                    "name": CLUSTER_FEATURES.get(k, {}).get("name", f"Cluster {k}")
                }
                for k, v in cluster_distribution.items()
            },
            "average_values": avg_values,
            "time_series": time_series[-50:]  # Son 50 Ã¶lÃ§Ã¼m
        }
        
        return jsonify(result)
        
    except Exception as e:
        log_error(f"GÃ¶l analizi hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500


@water_quality_bp.route("/api/water-quality/clusters/info", methods=["GET"])
def clusters_info():
    """TÃ¼m cluster'larÄ±n aÃ§Ä±klamalarÄ±nÄ± dÃ¶ndÃ¼r"""
    return jsonify({
        "status": "success",
        "total_clusters": 4,
        "clusters": CLUSTER_FEATURES,
        "model": "K-Means Unsupervised Learning",
        "features": ["NDWI", "WRI", "Chlorophyll-a", "Turbidity"],
        "data_source": "Sentinel-2 Satellite (2018-2024)"
    })


@water_quality_bp.route("/api/water-quality/all-lakes-summary", methods=["GET"])
def all_lakes_summary():
    """TÃ¼m gÃ¶ller iÃ§in Ã¶zet su kalitesi bilgisi"""
    try:
        # MongoDB'den su kalitesi verilerini al
        from database import get_database
        
        db = get_database()
        
        # Her gÃ¶l iÃ§in cluster daÄŸÄ±lÄ±mÄ±
        lakes_summary = []
        
        # TÃ¼m gÃ¶lleri al
        for lake_key, lake_info in LAKE_INFO.items():
            lake_id = lake_info.get('id')
            lake_name = lake_info.get('name', f'GÃ¶l {lake_id}')
            
            # Bu gÃ¶l iÃ§in su kalitesi verilerini al
            quality_data = list(db['water_quality_measurements'].find({'lake_id': lake_id}).limit(100))
            
            if quality_data:
                # Cluster daÄŸÄ±lÄ±mÄ±nÄ± hesapla
                cluster_counts = {}
                for record in quality_data:
                    cluster = record.get('cluster', 0)
                    cluster_counts[cluster] = cluster_counts.get(cluster, 0) + 1
                
                # BaskÄ±n cluster
                if cluster_counts:
                    dominant_cluster = max(cluster_counts, key=cluster_counts.get)
                    
                    lakes_summary.append({
                        "lake_id": int(lake_id),
                        "lake_name": lake_name,
                        "measurements": len(quality_data),
                        "dominant_cluster": dominant_cluster,
                        "cluster_distribution": cluster_counts
                    })
                else:
                    lakes_summary.append({
                        "lake_id": int(lake_id),
                        "lake_name": lake_name,
                        "measurements": 0,
                        "dominant_cluster": None,
                        "cluster_distribution": {}
                    })
        
        return jsonify({
            "status": "success",
            "total_lakes": len(lakes_summary),
            "lakes": lakes_summary
        })
        
    except Exception as e:
        log_error(f"Ã–zet hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500

